
# kafka的架构

![[Pasted image 20230313165155.png]] 
发布、订阅模式

kafka发送端采用push模式将消息发送到broker
kafka消费端采用pull模式订阅并消费消息

消费者组：Kafka的消费者组是指一组消费者共同消费同一个主题（topic）的不同分区（partition）的消息。一个分区只能由组内一个消费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。

- broker：一个broker是由zk管理的单个kafka节点，一组broker组成了kafka集群
- Topic：主题，生产者和消费者通过此进行对接
- Partition：分区，为了实现扩展性，一个topic可以分布在多个broker上，一个topic可以分为多个Partition，每个partition都是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证同一个partition中的消息顺序，不保证一个topic的整体（多个partition之间）的顺序。生产者和消费者使用时可以指定topic中的具体partition。
-   **副本**：在kafka中，每个主题可以有多个分区，每个分区又可以有多个副本。
-   **offset**：消费偏移量，topic中的**每个分区都是有序且顺序不可变的记录集**，并且不断地追加到结构化的log文件。分区中的每一个记录都会分配一个id号来表示顺序，我们称之为offset，offset用来唯一的标识分区中每一条记录。可以设置为“自动提交”与“手动提交”。
-   zk进行集群管理，选举leader

关系：topic&Partition

一个topic为一类消息，每条消息必须指定一个topic。物理上，一个topic分成一个或多个partition，每个partition有多个副本分布在不同的broker中，

每个partition在存储层面是一个append log文件，发布到此partition的消息会追加到log文件的尾部，为顺序写入磁盘（顺序写磁盘比随机写内存的效率还要高）。每条消息在log文件中的位置成为offset（偏移量），offset为一个long型数字，唯一标记一条消息。

每个消费者唯一保存的元数据是offset值，这个位置完全为消费者控制，因此消费者可以采用任何顺序来消费记录。


# kafka为什么有那么大的吞吐量？

#### 1、并行处理

利用 Partition (分区)实现并行处理，同时不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。

#### 2、顺序写Kafka

**Kafka**写数据的时候，**Kafka**的消息是不断追加到**文件末尾**的，在磁盘顺序写比在内存的随机写性能更好，这个特性使**Kafka**可以充分利用磁盘的顺序读写性能。

Kafka 直接将数据写到了文件系统的日志中：并没有经过缓存

-   写操作：将数据顺序追加到文件中
-   读操作：从文件中读取到内存中

3、零拷贝的使用

写操作：采用mmap的方式，从socket中得到的数据，经过用户态处理直接，直接写入到内核空间，再写入到磁盘空间上。
读操作：从磁盘上拷贝数据放入内核的缓冲区中，然后内核采用sendfile() 直接从内核态copy到socket缓冲区，然后由网卡发出，减少上下文切换。



# kafka的副本

kafka的副本分类：

1、AR（Assigned Repllicas）一个partition的所有副本（就是replica（复制品），不区分leader或follower）

2、ISR（In-Sync Replicas）能够和 leader 保持同步的 follower + leader本身 组成的集合。
**Kafka会在Zookeeper上针对每个Topic维护一个称为ISR（in-sync replica，已同步的副本）的集合，该集合中是一些分区的副本。只有当这些副本都跟Leader中的副本同步了之后，kafka才会认为消息已提交，并反馈给消息的生产者。**

3、OSR（Out-Sync(同步) Relipcas）不能和 leader 保持同步的 follower 集合

ISR和OSR的follower集合可以相互转换，新加入的Follower也会先存放在OSR中。


## HW、LEO代表什么

HW：**代表消费者可以消费HW之前的消息**。通过它可以得知副本中已提交或已备份消息的范围，leader副本中的HW，决定了消费者能消费的最新消息能到哪个offset。

LEO：**标识当前日志文件中下一条待写入的消息的offset。**上图中offset为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的offset值加1.

分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。


## 发送消息的分区策略有哪些

#### 1）轮询策略（默认）

轮询策略是默认的策略，故而也是使用最频繁的策略，它能最大限度保证所有消息都平均分配到每一个分区。除非有特殊的业务需求，否则使用这种方式即可。

#### 2）随机策略

随机策略，也就是每次都随机地将消息分配到每个分区。其实大概就是先得出分区的数量，然后每次获取一个随机数，用该随机数确定消息发送到哪个分区。

#### 3）hash（Key）

按键保存策略，就是当生产者发送数据的时候，可以指定一个key，计算这个key的hashCode值，按照hashCode的值对不同消息进行存储。

#### 4）自定义分区器

实现partitioner接口。项目中为了保持订单消息的顺序，我们需要把同一个订单数据放入到同一个分区中。根据订单id取hash值，然后对分区取余。



### Kafka分区过多引发的弊端

1）内存开销

客户端producer有个参数batch.size默认为 16KB。它会为**每个分区缓存消息**，一旦批次数满了后，将消息批量发出。一般来说，这个设计是用于提升吞吐性能的。但是由于这个参数是partition级别的，如果分区数越多，这部分缓存所需的内存占用也会越多。

2）文件句柄开销

每个分区在文件系统上会对应一个目录，用于存储维护kafka数据日志，如果分区数越多，所需要保持打开状态的文件句柄数也就越多。

3）分区太多，副本随之增多

一个 2 节点的kafka集群中存在 2000 个partition，每个partition拥有 2 个副本。当其中一个broker意外宕机，所有 1000 个partition同时变得不可用。假设每一个partition恢复时间是 5ms，那么 1000 个partition的恢复时间将会花费 5 秒钟，这可能对用户来说就会有一个明显的感知了



# Kafka如何保证有且仅有一次？


使用事务和幂等生产者（Transactional and Idempotent Producer）：Kafka 的生产者支持事务和幂等特性。使用事务和幂等生产者，可以保证消息被有且仅有地传输一次，同时也能够保证消息的顺序性。在生产者发送消息时，可以将多个操作（如消息发送和提交事务）封装成一个事务，如果其中任意一个操作失败，则整个事务将被回滚，从而保证消息不会重复发送或丢失。幂等特性可以确保同一条消息不会被重复发送，即使发生了重试或者网络抖动等异常情况。使用事务和幂等生产者，需要配置相应的参数和开启相应的功能，



## redis 如何实现消息队列

https://so1n.me/2021/04/23/%E4%BD%BF%E7%94%A8Redis%E5%BD%93%E5%81%9A%E9%98%9F%E5%88%97/



`Pub/Sub`原本的意思是发布/订阅, 生成者发布一条消息, 多个订阅的消费者都能得到这条消息.

1) 缺点-作为一个通道，不会存储任何数据，如果消费者下线了，这个消息就再也没有办法回到消费者手上。那当前的消息就会被丢弃了, 这个直接违背了消息队列的原则.  
2) 缺点： 存在消息积压，发布者发布消息后, `Redis`会发给消费者, 如果消费者处理不及时, 会把消息积压在发送给消费者的缓冲区之中, 如果这个缓冲区的数量达到配置的上限, 那么`Redis`就会认为这个消费者可能失去了消费能力, 与他断开连接, 所以`Pub/Sub`方案是不可取的.

`Stream`是一个完备的分布式内存消息队列, 如果用过其他类似的内存消息队列。
1）发布/订阅模式:  
了解了`Pub/Sub`后, 可以知道在消息队列中使用发布/订阅模式可以做一些兜底的操作, 比如消息需要比较及时响应时, 有多个消费者在消费同一个消息, 即使有一个挂了, 其他的消费者也能正常处理消息.

2）消费监控  
在`Stream`中带有一个简单的消息监控, 可以看到每个消费组有多少个消费者, 当前消费到哪条信息

3）ACK  
ack逻辑, 解决了消费者处理消息过程中挂了造成消息丢失的问题

从消费者监控中可以看到, test_group1中还有两条pending的消息, 这些都是消费者还未ack的消息, 当消费者启动时, 需要通过命令`xpending`主动查看尚在pending的消息, 根据消息id, 再次消费并提交ACK.这样就可以确保所有消息都能被消费者正常消费, 不会因为消费者本身的问题造成漏消费.

3）消息堆积
在创建`Stream`的队列时, 规定队列的最长长度, 当队列里面积压的消息超过限度时, 旧消息就会被扔掉了。


# kafka集群中zk的作用

1）kafka使用zk来管理broker和topic的元数据信息
- 在broker启动的时候会向zk中注册自己的信息，同时在broker宕机的时候zk会移除这些基本信息
- topic的信息：包括名称、分区数、副本数。
- offset的管理，在kafka的消费者进行消费时候，在zk中记录自己消费到哪个offset。
2）进行协调leader选举
- 当一个broker或者分区的主副本可不用的时候，zk会通知其他broker进行重新选举新的leader
- 一旦新的主副本被选取得到，那么kafka会更新元数据并且广播给所有的broker。
3）进行负载均衡
-   对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生 消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消 费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数 量来实现动态负载均衡。

# kafka如何保证消息的顺序性

总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法: 
⚫ 1 个 Topic 只对应一个 Partition。  
⚫ 发送消息的时候指定 key/Partition。将两个消息发送到同一个partition中。

