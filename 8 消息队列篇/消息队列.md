## 消息队列的作用

1) **解耦**：生产者产出一条数据之后，直接丢到mq中，让后面的消费者去消费，自己不需要考虑是否调用成功、失败超时等情况。
2) **削峰：** 为了防止流量过大，一下子把服务给打垮，放入到队列中，让系统慢慢消费。这里我们处理商品特征的时候用到了。
4) **异步：** 一个写操作牵涉到，A B C D四个系统的写库。可以将A系统写完之后，直接将请求返回，然后将数据放到消息队列中，其他三个服务取消费更新自己的数据库。

## 缺点

1）系统可用性低：如果消息队列崩溃，如何保证？
2）系统复杂度高：如何保证没有重复消费？如何保证消息的顺序性？如何进行消息不出现丢失？
3）数据如何保证一致性：比如在刚才说的异步里面，A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，导致数据不正确。

## 常见的消息队列-kafka


最高能达到百万级别，一般配合大数据类的系统来进行实时数据计算、日志采集等场景

**为什么kafka要求topic不要太多？**

在同等机器的时候，kafka尽量保证topic不要太多，topic增多，分区随之增多，随之存储碎片化严重。由于kafka的读写是以分区粒度进行的，单机层面的随机写增多。如果需要支持大规模的topic，需要增加更多的机器资源。


kafka如何保证系统的高可用？

采用多副本机制来保证系统的高可用。

Kafka通过多副本机制来保证高可用性。具体来说，一个分区可以配置一个leader副本和多个follower副本（replica），每个副本都是完整的分区拷贝。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

在正常情况下，每个分区都只有一个leader副本，其余的副本都是follower副本，follower副本通过异步的方式向leader副本同步数据。当leader副本出现故障或宕机时，Kafka会从follower副本中选举一个副本作为新的leader副本，并且通知其他follower副本开始从新leader副本同步数据。

通过这种多副本机制，Kafka可以在一个节点宕机时，仍然保证分区的可用性和数据的完整


为什么只能读写 leader？
	**如果可以随意读写每个 follower，那么就要 关心 数据一致性的问题**，系统复杂度太高，很容易出问题。



kafka如何保证消息不被重复消费？

1）**消费者维护的一个消费的offset**

当每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，**每隔一段时间**，会把自己消费过的消息的 offset 提交一下，表示已经消费过了，如果消费者出现重启，就能保证从上次消费到的 offset 继续消费。

由于每个消费者组中每个消费者实例都会独立保存自己消费到的offset，因此可以保证同一分区的消息不会被多个消费者实例重复消费。

另外，Kafka还提供了两种保证消息不被重复消费的机制：幂等性和事务。幂等性是指消费者在消费消息时，可以确保相同的消息不会被重复消费。事务则是指在一个事务中，所有的操作要么全部成功，要么全部失败，从而确保消息的一致性和可靠性。这两种机制都需要在生产者端进行配置和使用。


2）幂等性：相同的消息不会被重复消费
3）事务：在一个事务中，所有的操作要么全部成功，要么全部失败

首先，生产者可以通过在消息中添加唯一的 ID 来保证消息的幂等性。每条消息都应该有一个唯一的 ID，生产者通过这个 ID 来保证消息只会被消费一次。Kafka 的消费者会记录已经消费过的消息 ID，当重复消费时会直接跳过。

其次，Kafka 还提供了事务支持。生产者可以通过使用事务将多个消息的发送视为一个原子操作，如果其中某个消息发送失败，则整个事务都会回滚。事务保证了多个消息的原子性，从而保证了消息的幂等性。


kafka如何保证消息的顺序性

写 N 个内存partion，具有相同 key 的数据都到同一个partion；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。


如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？

#### 消费端弄丢了数据

 Kafka 会自动提交 offset，那么只要**关闭自动提交** offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是**可能会有重复消费**，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性（唯一键的使用）就好了。

#### 生产者弄丢了数据

1）针对单个数据来说，在发送到kafka的时候，先进行消息持久化。

2）从集群的角度，分区的副本要大于2，并且分区中至少一个follower节点要跟leader保持不掉队联系，在进行响应码为acks=all的时候，才能进行消息写入。这样至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。



kafka的事务


Kafka 事务消息则是用在一次事务中需要发送多个消息的情况，保证**多个消息之间的事务约束**，即多条消息要么都发送成功，要么都发送失败。

**Kafka 的事务基本上是配合其幂等机制来实现 Exactly Once 语义的**

我们知道消息可靠性有三种，分别是最多一次、恰好一次、最少一次，之前在消息队列连环问的文章我已经提到了基本上我们**是用最少一次然后配合消费者端的幂等**来实现恰好一次。

消息恰好被消费一次当然我们所有人追求的，但是之前文章我已经从各方面已经分析过了，基**本上难以达到**。

kafka中实现的恰好一次是在某个铁定场景下：**Kafka 作为消息源，然后做了一番操作之后，再写入 Kafka 中。**

**就是通过幂等**，和我们在业务上实现的一样通过一个唯一 Id， 然后记录下来，如果已经记录过了就不写入，这样来保证恰好一次。

